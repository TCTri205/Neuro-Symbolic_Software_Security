{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèãÔ∏è NSSS Security Auditor - Colab Trainer (Complete Workflow)\n",
    "\n",
    "This notebook provides a robust, automated workflow to fine-tune the Qwen2.5-Coder model for security auditing.\n",
    "\n",
    "**Workflow Steps:**\n",
    "1.  **Environment Setup:** Auto-repairing installation of Unsloth and GPU drivers.\n",
    "2.  **Data Preparation:** Downloads real CVE fixes and generates training data.\n",
    "3.  **Baseline Evaluation:** Assess model performance before training.\n",
    "4.  **Fine-tuning:** Trains the model using QLoRA on T4 GPU.\n",
    "5.  **Final Evaluation:** Verifies improvements and generates a comparison report.\n",
    "\n",
    "**Usage:** Simply select **Runtime -> Run all**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# @title 1. Setup Repository\n",
    "\n",
    "# Clone or update the repository\n",
    "if [ ! -d \"/content/app\" ]; then\n",
    "    echo \"üì• Cloning repository...\"\n",
    "    git clone https://github.com/TCTri205/Neuro-Symbolic_Software_Security.git /content/app\n",
    "else\n",
    "    echo \"üîÑ Updating repository...\"\n",
    "    cd /content/app && git pull origin main\n",
    "fi\n",
    "\n",
    "cd /content/app\n",
    "echo \"‚úÖ Repository ready at: $(pwd)\"\n",
    "echo \"üìç Current branch: $(git branch --show-current)\"\n",
    "echo \"üìå Latest commit: $(git log -1 --oneline)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1.1 Mount Drive & Configure Smart Cache\n",
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"üîó Configuring Persistence...\")\n",
    "\n",
    "# 1. Mount Drive\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# 2. Define Paths\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/NSSS_Project\"\n",
    "APP_ROOT = \"/content/app\"\n",
    "HF_CACHE_DRIVE = os.path.join(DRIVE_ROOT, \"hf_cache\")\n",
    "HF_CACHE_LOCAL = \"/root/.cache/huggingface\"\n",
    "\n",
    "# 3. Create Directories on Drive\n",
    "os.makedirs(os.path.join(DRIVE_ROOT, \"data\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(DRIVE_ROOT, \"outputs\"), exist_ok=True)\n",
    "os.makedirs(HF_CACHE_DRIVE, exist_ok=True)\n",
    "\n",
    "# 4. Symlink Data & Outputs (App <-> Drive)\n",
    "for folder in [\"data\", \"outputs\"]:\n",
    "    local_path = os.path.join(APP_ROOT, folder)\n",
    "    drive_path = os.path.join(DRIVE_ROOT, folder)\n",
    "    \n",
    "    # Remove local folder if it exists (empty from git clone)\n",
    "    if os.path.exists(local_path) and not os.path.islink(local_path):\n",
    "        shutil.rmtree(local_path)\n",
    "        \n",
    "    # Link to Drive\n",
    "    if not os.path.exists(local_path):\n",
    "        os.symlink(drive_path, local_path)\n",
    "        print(f\"   ‚úÖ Linked {folder}: {local_path} -> {drive_path}\")\n",
    "\n",
    "# 5. Symlink HF Cache (Avoid re-downloading Base Model)\n",
    "if os.path.exists(HF_CACHE_LOCAL) and not os.path.islink(HF_CACHE_LOCAL):\n",
    "    shutil.rmtree(HF_CACHE_LOCAL)\n",
    "\n",
    "if not os.path.exists(HF_CACHE_LOCAL):\n",
    "    os.makedirs(os.path.dirname(HF_CACHE_LOCAL), exist_ok=True)\n",
    "    os.symlink(HF_CACHE_DRIVE, HF_CACHE_LOCAL)\n",
    "    print(f\"   ‚úÖ Linked HF Cache: {HF_CACHE_LOCAL} -> {HF_CACHE_DRIVE}\")\n",
    "\n",
    "print(\"üöÄ Persistence Configured! Data and Models will be saved to Drive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# @title 2. Fix Unsloth Installation\n",
    "echo \"üîß Cleaning Unsloth stack...\"\n",
    "\n",
    "# 1. Uninstall existing packages to prevent conflicts\n",
    "pip uninstall -y unsloth unsloth_zoo 2>/dev/null || true\n",
    "\n",
    "# 2. Remove cached files that might be corrupt\n",
    "rm -rf /usr/local/lib/python3.12/dist-packages/unsloth* 2>/dev/null || true\n",
    "rm -rf /usr/local/lib/python3.12/dist-packages/__pycache__/unsloth* 2>/dev/null || true\n",
    "\n",
    "# 3. Clean project cache\n",
    "cd /content/app\n",
    "find . -name \"*.pyc\" -delete 2>/dev/null || true\n",
    "find . -name \"__pycache__\" -type d -exec rm -rf {} + 2>/dev/null || true\n",
    "\n",
    "echo \"‚úÖ Cleanup complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# @title 3. Install System Dependencies\n",
    "cd /content/app\n",
    "echo \"üì¶ Installing system dependencies...\"\n",
    "pip install -q -r requirements.txt\n",
    "echo \"‚úÖ System dependencies installed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# @title 4. Install Unsloth & GPU Optimizations\n",
    "\n",
    "# 1. Install dependencies first to ensure stability\n",
    "echo \"üì¶ Installing core dependencies...\"\n",
    "pip install -q transformers>=4.51.3 datasets>=3.4.1 bitsandbytes>=0.45.5 peft>=0.18.0 accelerate>=0.34.1\n",
    "\n",
    "# 2. Install TRL (specific version range)\n",
    "pip install -q \"trl>=0.18.2,<0.25.0\"\n",
    "\n",
    "# 3. Install Unsloth without auto-dependencies (prevents xformers build errors)\n",
    "echo \"üì¶ Installing Unsloth...\"\n",
    "pip install -q \"unsloth @ git+https://github.com/unslothai/unsloth.git\" --no-deps\n",
    "\n",
    "# 4. Install unsloth_zoo explicitly\n",
    "pip install -q \"unsloth_zoo>=2026.1.4\"\n",
    "\n",
    "echo \"üì¶ Verifying Unsloth stack...\"\n",
    "pip list | grep -E \"(unsloth|transformers|bitsandbytes|trl|torch)\" || true\n",
    "echo \"‚úÖ Unsloth stack installed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Environment Verification\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç ENVIRONMENT VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. GPU Check\n",
    "print(f\"\\n1Ô∏è‚É£ GPU Status:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   ‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "    print(f\"   üéÆ Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"   ‚ùå GPU NOT AVAILABLE!\")\n",
    "    print(\"   üëâ Go to Runtime ‚Üí Change runtime type ‚Üí Select T4 GPU\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 2. Unsloth Import Check\n",
    "print(f\"\\n2Ô∏è‚É£ Unsloth Status:\")\n",
    "try:\n",
    "    from unsloth import FastLanguageModel\n",
    "    print(\"   ‚úÖ Unsloth imported successfully!\")\n",
    "    os.environ['INFERENCE_PROVIDER'] = 'local'\n",
    "    os.environ['INFERENCE_MODEL'] = 'unsloth/Qwen2.5-Coder-7B-Instruct-bnb-4bit'\n",
    "    print(\"   üéØ Provider: LOCAL (GPU-accelerated)\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Unsloth import failed: {e}\")\n",
    "    print(\"   üîÑ Will use fallback provider (Gemini)\")\n",
    "    os.environ['INFERENCE_PROVIDER'] = 'gemini'\n",
    "    os.environ['INFERENCE_MODEL'] = 'gemini-1.5-flash'\n",
    "\n",
    "# 3. Project Path Check\n",
    "print(f\"\\n3Ô∏è‚É£ Project Setup:\")\n",
    "print(f\"   üìÇ Working Directory: {os.getcwd()}\")\n",
    "if os.path.exists('/content/app/src'):\n",
    "    print(\"   ‚úÖ Project structure valid\")\n",
    "    sys.path.insert(0, '/content/app')\n",
    "else:\n",
    "    print(\"   ‚ùå Project structure invalid!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üöÄ Ready to proceed with provider: {os.environ['INFERENCE_PROVIDER'].upper()}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Configure LLM Provider (with Fallback)\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "print(\"üîë Configuring LLM Provider...\")\n",
    "\n",
    "provider = os.environ.get('INFERENCE_PROVIDER', 'local')\n",
    "\n",
    "if provider == 'local':\n",
    "    print(\"‚úÖ Using LOCAL inference (GPU-accelerated)\")\n",
    "    print(\"   No API keys needed for inference.\")\n",
    "else:\n",
    "    # Fallback to Gemini\n",
    "    print(f\"‚ö†Ô∏è Using FALLBACK provider: {provider.upper()}\")\n",
    "    try:\n",
    "        gemini_key = userdata.get('GEMINI_API_KEY')\n",
    "        if gemini_key:\n",
    "            os.environ['GEMINI_API_KEY'] = gemini_key\n",
    "            os.environ['LLM_PROVIDER'] = 'gemini'\n",
    "            # Force provider to Gemini if we have a key and local failed\n",
    "            os.environ['INFERENCE_PROVIDER'] = 'gemini'\n",
    "            print(\"   ‚úÖ Gemini API key configured from Secrets\")\n",
    "        else:\n",
    "            raise ValueError(\"GEMINI_API_KEY is empty\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed to get GEMINI_API_KEY: {e}\")\n",
    "        print(\"   üëâ Check Colab Secrets (Key icon on left). Ensure 'GEMINI_API_KEY' exists and 'Notebook access' is ON.\")\n",
    "        print(\"   üîÑ Falling back to MOCK provider for testing\")\n",
    "        os.environ['INFERENCE_PROVIDER'] = 'mock'\n",
    "\n",
    "# Optional: Configure HF_TOKEN for Gate Datasets\n",
    "try:\n",
    "    hf_token = userdata.get('HF_TOKEN')\n",
    "    if hf_token:\n",
    "        os.environ['HF_TOKEN'] = hf_token\n",
    "        print(\"\\n   ‚úÖ HF_TOKEN configured (Access to gated datasets enabled)\")\n",
    "except Exception:\n",
    "    print(\"\\n   ‚ÑπÔ∏è HF_TOKEN not found in Secrets (Using public datasets only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# @title 7. Prepare Training Dataset\n",
    "cd /content/app\n",
    "\n",
    "echo \"üìä Preparing training dataset...\"\n",
    "\n",
    "# Check if registry already exists with enough data\n",
    "if [ -f \"data/few_shot_registry.json\" ]; then\n",
    "    EXAMPLE_COUNT=$(python -c \"import json; data=json.load(open('data/few_shot_registry.json')); print(len(data.get('examples', [])))\")\n",
    "    echo \"   üìÇ Found existing registry on Drive with $EXAMPLE_COUNT examples\"\n",
    "    \n",
    "    if [ \"$EXAMPLE_COUNT\" -ge 2000 ]; then\n",
    "        echo \"   ‚úÖ Dataset ready! Skipping download.\"\n",
    "        exit 0\n",
    "    else\n",
    "        echo \"   ‚ö†Ô∏è Insufficient data ($EXAMPLE_COUNT < 2000), regenerating...\"\n",
    "    fi\n",
    "fi\n",
    "\n",
    "# Generate dataset from HuggingFace\n",
    "echo \"   üîÑ Downloading from HuggingFace & extracting vulnerable patterns...\"\n",
    "python scripts/prepare_cve_data.py --limit 2000\n",
    "\n",
    "# Verify output\n",
    "if [ -f \"data/few_shot_registry.json\" ]; then\n",
    "    FINAL_COUNT=$(python -c \"import json; data=json.load(open('data/few_shot_registry.json')); print(len(data.get('examples', [])))\")\n",
    "    echo \"   ‚úÖ Dataset prepared: $FINAL_COUNT examples\"\n",
    "else\n",
    "    echo \"   ‚ùå Dataset preparation failed!\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# @title 8. Run Baseline Evaluation\n",
    "cd /content/app\n",
    "\n",
    "echo \"üìä Running Baseline Evaluation...\"\n",
    "\n",
    "# Get provider from environment\n",
    "PROVIDER=\"${INFERENCE_PROVIDER:-local}\"\n",
    "MODEL=\"${INFERENCE_MODEL:-unsloth/Qwen2.5-Coder-7B-Instruct-bnb-4bit}\"\n",
    "\n",
    "# STRICT MODE: Stop if using Mock\n",
    "if [ \"$PROVIDER\" == \"mock\" ]; then\n",
    "    echo \"\"\n",
    "    echo \"==============================================================\"\n",
    "    echo \"‚ùå CRITICAL ERROR: System is using MOCK provider.\"\n",
    "    echo \"==============================================================\"\n",
    "    echo \"REASON: Neither Local GPU nor Gemini API Key is available.\"\n",
    "    echo \"\"\n",
    "    echo \"üëá TROUBLESHOOTING GUIDE:\"\n",
    "    echo \"1. GPU Check: Go to 'Runtime' -> 'Change runtime type'. Ensure 'T4 GPU' is selected.\"\n",
    "    echo \"2. Unsloth Check: Look at Cell 5 output. Did Unsloth import fail?\"\n",
    "    echo \"3. API Key Check: Look at Cell 6 output. Did it fail to get GEMINI_API_KEY?\"\n",
    "    echo \"   -> Click the Key icon üîë on the left sidebar.\"\n",
    "    echo \"   -> Ensure 'GEMINI_API_KEY' is listed.\"\n",
    "    echo \"   -> IMPORTANT: Toggle the 'Notebook access' switch to ON.\"\n",
    "    echo \"\"\n",
    "    echo \"Execution stopped to prevent invalid evaluation on fake data.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"   üéØ Provider: $PROVIDER\"\n",
    "echo \"   ü§ñ Model: $MODEL\"\n",
    "\n",
    "python scripts/evaluate_model.py \\\n",
    "    --provider \"$PROVIDER\" \\\n",
    "    --model \"$MODEL\" \\\n",
    "    --registry data/few_shot_registry.json\n",
    "\n",
    "# Save baseline report\n",
    "if [ -f \"outputs/evaluation_report.json\" ]; then\n",
    "    mv outputs/evaluation_report.json outputs/report_baseline.json\n",
    "    echo \"   ‚úÖ Baseline saved to outputs/report_baseline.json\"\n",
    "else\n",
    "    echo \"   ‚ö†Ô∏è Baseline evaluation produced no output\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 9. Fine-tune Security Model\n",
    "import os\n",
    "\n",
    "ENABLE_TRAINING = False  # @param {type:\"boolean\"}\n",
    "\n",
    "if ENABLE_TRAINING:\n",
    "    print(\"üéì Starting Fine-tuning...\")\n",
    "    print(\"   üìä Dataset: 2000 examples\")\n",
    "    print(\"   ü§ñ Base Model: Qwen/Qwen2.5-Coder-7B-Instruct\")\n",
    "    print(\"   üíæ Output: outputs/qwen-security-model\")\n",
    "    print(\"   ‚è±Ô∏è Estimated Time: 15-20 minutes\\n\")\n",
    "\n",
    "    !python scripts/train_model.py \\\n",
    "        --registry data/few_shot_registry.json \\\n",
    "        --output outputs/qwen-security-model \\\n",
    "        --model Qwen/Qwen2.5-Coder-7B-Instruct\n",
    "    \n",
    "    if os.path.exists(\"outputs/qwen-security-model\"):\n",
    "        print(\"\\n‚úÖ Fine-tuning completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Fine-tuning failed!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Training skipped (ENABLE_TRAINING = False).\")\n",
    "    print(\"   Enable the checkbox and rerun this cell to fine-tune.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 10. Run Final Evaluation\n",
    "import os\n",
    "\n",
    "# Determine if we should run evaluation\n",
    "should_run = False\n",
    "if 'ENABLE_TRAINING' in locals() and ENABLE_TRAINING:\n",
    "    should_run = True\n",
    "elif os.path.exists(\"outputs/qwen-security-model/adapter_config.json\"):\n",
    "    print(\"üìÇ Found existing fine-tuned model.\")\n",
    "    should_run = True\n",
    "\n",
    "if should_run:\n",
    "    print(\"üìä Running Final Evaluation...\")\n",
    "    # Always use LOCAL provider for post-training eval\n",
    "    !python scripts/evaluate_model.py \\\n",
    "        --provider local \\\n",
    "        --model outputs/qwen-security-model \\\n",
    "        --registry data/few_shot_registry.json\n",
    "\n",
    "    if os.path.exists(\"outputs/evaluation_report.json\"):\n",
    "        !mv outputs/evaluation_report.json outputs/report_final.json\n",
    "        print(\"‚úÖ Final evaluation saved to outputs/report_final.json\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Final evaluation produced no output\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping Final Evaluation (No trained model found).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 11. Compare Results & Generate Report\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìà TRAINING RESULTS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load reports\n",
    "baseline_path = '/content/app/outputs/report_baseline.json'\n",
    "final_path = '/content/app/outputs/report_final.json'\n",
    "\n",
    "if not os.path.exists(baseline_path):\n",
    "    print(\"‚ùå Baseline report not found!\")\n",
    "elif not os.path.exists(final_path):\n",
    "    print(\"‚ö†Ô∏è Final report not found (Training skipped?).\")\n",
    "    print(\"üìä Showing Baseline Results Only:\\n\")\n",
    "    \n",
    "    with open(baseline_path) as f:\n",
    "        baseline = json.load(f)\n",
    "        metrics = baseline['metrics']\n",
    "        print(f\"Accuracy:        {metrics['accuracy']:.2%}\")\n",
    "        print(f\"JSON Validity:   {metrics['json_validity_rate']:.2%}\")\n",
    "        print(f\"False Positive:  {metrics['fpr']:.2%}\")\n",
    "        print(f\"False Negative:  {metrics['fnr']:.2%}\")\n",
    "else:\n",
    "    with open(baseline_path) as f:\n",
    "        baseline = json.load(f)\n",
    "    with open(final_path) as f:\n",
    "        final = json.load(f)\n",
    "    \n",
    "    b_metrics = baseline['metrics']\n",
    "    f_metrics = final['metrics']\n",
    "    \n",
    "    # Calculate improvements\n",
    "    def delta(metric_name):\n",
    "        b = b_metrics.get(metric_name, 0)\n",
    "        f = f_metrics.get(metric_name, 0)\n",
    "        diff = f - b\n",
    "        pct = (diff / b * 100) if b > 0 else 0\n",
    "        return f, diff, pct\n",
    "    \n",
    "    print(\"\\nüìä Metric Comparison:\\n\")\n",
    "    print(f\"{'Metric':<20} {'Baseline':<12} {'Fine-tuned':<12} {'Change':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    acc_f, acc_d, acc_p = delta('accuracy')\n",
    "    print(f\"{'Accuracy':<20} {b_metrics.get('accuracy',0):<12.2%} {acc_f:<12.2%} {acc_d:+.2%} ({acc_p:+.1f}%)\")\n",
    "    \n",
    "    json_f, json_d, json_p = delta('json_validity_rate')\n",
    "    print(f\"{'JSON Validity':<20} {b_metrics.get('json_validity_rate',0):<12.2%} {json_f:<12.2%} {json_d:+.2%} ({json_p:+.1f}%)\")\n",
    "    \n",
    "    fpr_f, fpr_d, fpr_p = delta('fpr')\n",
    "    print(f\"{'False Positive':<20} {b_metrics.get('fpr',0):<12.2%} {fpr_f:<12.2%} {fpr_d:+.2%} ({fpr_p:+.1f}%)\")\n",
    "    \n",
    "    fnr_f, fnr_d, fnr_p = delta('fnr')\n",
    "    print(f\"{'False Negative':<20} {b_metrics.get('fnr',0):<12.2%} {fnr_f:<12.2%} {fnr_d:+.2%} ({fnr_p:+.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Overall assessment\n",
    "    if acc_d > 0:\n",
    "        print(\"üéâ SUCCESS! Fine-tuning improved model accuracy!\")\n",
    "    elif acc_d == 0:\n",
    "        print(\"‚ö†Ô∏è No significant change in accuracy\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Accuracy decreased - may need more training data or epochs\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Save comparison report\n",
    "    comparison = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'baseline': baseline,\n",
    "        'final': final,\n",
    "        'improvements': {\n",
    "            'accuracy': {'absolute': acc_d, 'relative_pct': acc_p},\n",
    "            'json_validity': {'absolute': json_d, 'relative_pct': json_p},\n",
    "            'fpr': {'absolute': fpr_d, 'relative_pct': fpr_p},\n",
    "            'fnr': {'absolute': fnr_d, 'relative_pct': fnr_p}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('/content/app/outputs/comparison_report.json', 'w') as f:\n",
    "        json.dump(comparison, f, indent=2)\n",
    "    \n",
    "    print(\"\\nüíæ Detailed comparison saved to: outputs/comparison_report.json\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
